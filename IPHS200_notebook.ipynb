{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724c989b",
   "metadata": {},
   "source": [
    "# Topic Modeling on Alternative Energy Tweets\n",
    "\n",
    "This notebook demonstrates how topic modeling can be used to analyze public discourse on alternative energy (e.g., Solar, Lithium) using NLP techniques.\n",
    "The example simulates part of a project done on global vs Bangladesh energy trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf49cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Twitter data loading \n",
    "# df = pd.read_csv('data/tweets.csv')\n",
    "# Simulated tweet data\n",
    "df = pd.DataFrame({\n",
    "    'tweet': [\n",
    "        'Tesla is revolutionizing lithium battery tech! #EV',\n",
    "        'Solar panels are getting cheaper every year! https://solar.com',\n",
    "        'Bangladesh explores wind energy potential.',\n",
    "        'Hydrogen fuel is the future. Clean and efficient!',\n",
    "        'Solar and wind can power the world ðŸŒ'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Clean the text\n",
    "def clean_tweet(tweet):\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)\n",
    "    tweet = re.sub(r'\\@\\w+|\\#', '', tweet)\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
    "    return tweet.lower()\n",
    "\n",
    "df['clean_text'] = df['tweet'].apply(clean_tweet)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['tokens'] = df['clean_text'].apply(lambda x: [word for word in word_tokenize(x) if word not in stop_words and len(word) > 3])\n",
    "df[['clean_text', 'tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "# Create dictionary and corpus\n",
    "dictionary = corpora.Dictionary(df['tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['tokens']]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = models.LdaModel(corpus, num_topics=2, id2word=dictionary, passes=10)\n",
    "topics = lda_model.print_topics()\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Visualize topics\n",
    "vis_data = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(vis_data)  # Will work in Jupyter Notebook\n",
    "# pyLDAvis.save_html(vis_data, 'visualizations/lda_visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595cb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(X.toarray())\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(components[:,0], components[:,1], alpha=0.7)\n",
    "plt.title('PCA of Tweets on Alternative Energy')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef9e5b",
   "metadata": {},
   "source": [
    "### âœ… Summary\n",
    "In this notebook, we:\n",
    "- Cleaned and tokenized tweets related to alternative energy.\n",
    "- Applied LDA topic modeling to identify themes.\n",
    "- Used PCA to visualize tweet clusters.\n",
    "\n",
    "This replicates part of the methodology from the research project on energy perspectives."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
